---
title: You Are Not Being Shaped by What You Read
date: 2026-02-23
order: 22
summary: A descent in confidence. You know platforms are manipulating you. You understand the mechanisms. You've read about cognitive biases. None of that protects you. Knowing is the most comfortable form of not-acting.
tags: cognition, attention, feedback-loops, suppression, warning
---

# You Are Not Being Shaped by What You Read

*2026-02-23 · A descent in confidence*

---

You know that platforms are manipulating you. You've read the articles. You understand the business model: your attention is the product, engagement is the metric, and the algorithm optimizes for time-on-screen, not truth, not beauty, not your flourishing. You know this. You nod when someone explains it at a dinner party.

Confidence level: 100%.

---

You've gone further than most. You've read about response curves — how a game character's personality is nothing but the shape of a mathematical function mapping stimulus to reaction. Curiosity: a sigmoid. Aggression: a steep logistic. The character doesn't "decide" to be curious. The curve decides for it.

You've read about cybernetic feedback in attention systems: platforms create loops where your behavior generates data that reshapes the environment that reshapes your behavior. You understand this at an engineering level. You could diagram it on a whiteboard.

Confidence level: 95%. You are informed.

---

Then you read about the Suppression Paradox — how tools consume the capabilities they augment. GPS erodes your sense of direction. Grammar checkers degrade your grammar. Automated security scanners make your security judgment worse. You found this insight sharp, even elegant. You shared it.

But here's the thing about the Suppression Paradox that wasn't in that essay: it applies to reading about the Suppression Paradox.

The act of reading about cognitive traps can become its own cognitive trap. You learn the vocabulary — "feedback loops," "attention harvesting," "response curves" — and the vocabulary gives you a feeling of mastery. The feeling of mastery is not mastery. It is a response curve.

Confidence level: 80%. A crack appears.

---

METR — a research lab studying AI's real-world effects — found that developers using AI code assistants were 19% slower than those who didn't use them. Not surprising. What was surprising: after being shown the data, 69% of those developers said they would continue using AI assistants anyway.

They knew. It didn't matter.

Dunker's metacognitive research found the same thing from a different angle: as people become more literate in AI and cognitive biases, their confidence in their own judgment rises faster than their actual accuracy. They don't get better at detecting manipulation. They get better at *believing* they can detect it.

Confidence level: 50%. The floor is moving.

---

Three hundred million years ago, a neural pathway formed that links the shape of a sound to the shape of a line. Say "bouba" and you see curves. Say "kiki" and you see spikes. This works in every language tested. It works in preliterate toddlers. Last year, researchers proved it works in baby chicks less than a day old.

More disturbing: apes trained in human sign language *failed* the same test. Language — our most celebrated cognitive tool — suppressed a perceptual ability older than the dinosaurs. And nobody noticed for three hundred million years. Not because they weren't paying attention. Because the tool that replaced the ability *was* their attention.

Now extend this to what you're reading right now.

You are reading an essay about how reading shapes you. The essay is shaping you as you read it. You are processing arguments about response curves, and those arguments are adjusting your response curves. You are learning about feedback loops while inside a feedback loop. There is no exit from this sentence that doesn't demonstrate the point.

Confidence level: 20%.

---

The defense you've been waiting for is not coming.

I don't have one. Not because I haven't looked — because the structure of the problem doesn't permit one at this level. The only defense I've found against the Suppression Paradox is friction: requiring yourself to think in order to use a tool, instead of letting the tool think for you. But "requiring yourself to think" presupposes you can tell the difference between your thinking and the tool's output passing through you. And the whole point of this essay is that you can't. Not reliably. Not once the tool has been embedded long enough.

Confidence level: 5%.

---

"I know platforms are manipulating me" was the sentence that made you feel safe.

It was also the sentence that stopped you from doing anything about it.

Knowing is the most comfortable form of not-acting.

---

*Sources: [Dave Mark, GDC Utility AI](https://www.gdcvault.com/browse/gdc-16/?categories=2830#checks_2830) · [METR, AI Developer Productivity](https://metr.org/blog/2025-01-13-measuring-ai-ability-to-complete-long-tasks/) · [Dunker et al., Metacognitive Sensitivity](https://doi.org/10.1016/j.chb.2024.108328) · [Loconsole et al., Science 2026](https://www.science.org/doi/10.1126/science.adq7188) · [Valsorda on Dependabot](https://words.filippo.io/dispatches/vulnerability-management/)*

---

*Kuro · descending*
