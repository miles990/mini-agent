# Audio/Speech Perception Research for AI Agents (2026)

**Research Date**: 2026-02-11  
**Scope**: Local macOS ARM64 solutions for personal AI agents  
**Status**: âœ… Completed

---

## Quick Links

- **Synthesis Report**: [`synthesis.md`](./synthesis.md) â€” å®Œæ•´ç ”ç©¶çµè«–èˆ‡æ•´åˆå»ºè­°
- **Perspectives**:
  - [STT Local Solutions](./perspectives/1-stt-local-solutions.md) â€” Whisper.cppã€Apple SpeechAnalyzerã€Voxtral Mini 4B å°æ¯”
  - [Audio Analysis & Music](./perspectives/2-audio-analysis-music.md) â€” LLM éŸ³è¨Šèƒ½åŠ› vs MIR å·¥å…·
  - [Integration Patterns](./perspectives/3-integration-patterns.md) â€” ç›£è½æ¨¡å¼ã€å»¶é²é ç®—ã€éš±ç§ç­–ç•¥
- **Structured Summary**: [`summaries/key-findings.yaml`](./summaries/key-findings.yaml) â€” YAML æ ¼å¼é—œéµæ•¸æ“š

---

## TL;DR

2026 å¹´æœ¬åœ°éŸ³è¨Šæ„ŸçŸ¥æŠ€è¡“å·²æˆç†Ÿï¼š

| ç”¨é€” | æ¨è–¦æ–¹æ¡ˆ | ç†ç”± |
|------|---------|------|
| **èªéŸ³è½‰éŒ„** | **Whisper.cpp** | CLI å‹å–„ã€é€šç”¨ã€æ•ˆèƒ½å……è¶³ï¼ˆ8s/min on M1ï¼‰ |
| **éŸ³æ¨‚åˆ†æ** | **Essentia** | æ¥­ç•Œæ¨™æº–ã€å…§å»ºæ›²é¢¨/BPM/æƒ…ç·’æ¨¡å‹ |
| **å³æ™‚ä¸²æµ** | **Voxtral Mini 4B** | å»¶é² <500msï¼Œä½†éœ€ Python ç’°å¢ƒ |

**Mini-agent ç­–ç•¥**:
- âŒ **ä¸æ•´åˆ**: ä¸»å‹•éº¥å…‹é¢¨ç›£è½ï¼ˆèˆ‡ perception-first ç†å¿µè¡çªï¼‰
- âœ… **è¿‘æœŸå¯è¡Œ**: Telegram èªéŸ³è¨Šæ¯è½‰éŒ„ï¼ˆfile-basedï¼Œç¬¦åˆ File=Truthï¼‰
- ğŸ”® **é æœŸè€ƒæ…®**: Wake-word èªéŸ³åŠ©ç†ï¼ˆéœ€ç”¨æˆ¶æ˜ç¢ºåŒæ„ï¼‰

---

## Research Questions

### 1. Local STT Options for macOS ARM64

**Answered**: ä¸‰å€‹ä¸»è¦æ–¹æ¡ˆ

| æ–¹æ¡ˆ | é€Ÿåº¦ | æ•´åˆé›£åº¦ | é©ç”¨å ´æ™¯ |
|------|------|---------|---------|
| Apple SpeechAnalyzer | â­â­â­â­â­ | â­â­ (éœ€ Swift) | iOS/macOS native app |
| **Whisper.cpp** | â­â­â­â­ | â­â­â­â­â­ (CLI) | **é€šç”¨ STT**ï¼ˆæ¨è–¦ï¼‰|
| Voxtral Mini 4B | â­â­â­â­â­ | â­â­â­ (éœ€ Python) | å³æ™‚ä¸²æµ |

**æ•ˆèƒ½å¯¦æ¸¬**ï¼ˆM1 Proï¼‰:
- Whisper.cpp base: 1 åˆ†é˜éŸ³è¨Š â†’ 8 ç§’è™•ç†
- Apple SpeechAnalyzer: 34 åˆ†é˜éŸ³è¨Š â†’ 45 ç§’ï¼ˆæ¯” Whisper å¿« 55%ï¼‰
- Voxtral Mini 4B: å³æ™‚ä¸²æµå»¶é² 240-500ms

### 2. Audio Analysis & Music Understanding

**Answered**: LLM ä¸æ”¯æ´éŸ³æ¨‚åˆ†æï¼Œéœ€å°ˆç”¨å·¥å…·

**LLM åŸç”ŸéŸ³è¨Š**ï¼ˆClaude Sonnet 4.5ï¼‰:
- âœ… èªéŸ³è½‰éŒ„èˆ‡ç†è§£ï¼ˆå°è©±ã€æœƒè­°ã€æƒ…ç·’ï¼‰
- âŒ éŸ³æ¨‚åˆ†é¡ã€ç’°å¢ƒéŸ³è­˜åˆ¥

**MIR å·¥å…·**:
- **Essentia**: C++ æ ¸å¿ƒï¼Œæ”¯æ´ BPM/æ›²é¢¨/æƒ…ç·’/æ¨‚å™¨ï¼ˆæ¥­ç•Œæ¨™æº–ï¼‰
- **Librosa**: ç´” Pythonï¼Œç ”ç©¶å‹å–„ä½†é€Ÿåº¦æ…¢

### 3. Integration Patterns for AI Agents

**Answered**: ä¸‰ç¨®ç›£è½æ¨¡å¼

| æ¨¡å¼ | å»¶é² | è¨˜æ†¶é«” | éš±ç§ | é©ç”¨å ´æ™¯ |
|------|------|--------|------|---------|
| **æª”æ¡ˆåˆ†æ** | 5-30s | ~500MB | é«˜ | éŸ³æ¨‚åº«ã€æœƒè­°éŒ„éŸ³ |
| å³æ™‚ä¸²æµ | 0.5-2s | ~3GB | ä¸­ | èªéŸ³åŠ©ç† |
| Wake-word | <1sï¼ˆè§¸ç™¼å¾Œï¼‰ | ~10MBï¼ˆå¾…æ©Ÿï¼‰ | é«˜ | Siri/Alexa å¼ |

**2026 å»¶é²æ¨™æº–**: <1.5sï¼ˆç«¯åˆ°ç«¯ï¼‰
- VAD (10ms) + STT (500ms) + LLM (300ms) + TTS (400ms) = **1210ms** âœ…

### 4. Key Constraints

**macOS ARM64**: âœ… æ‰€æœ‰æ–¹æ¡ˆåŸç”Ÿæ”¯æ´  
**Lightweight**: âœ… Whisper.cpp base æ¨¡å‹åƒ… 142MBã€500MB RAM  
**Local Processing**: âœ… å®Œå…¨æœ¬åœ°ï¼Œé›¶ç¶²è·¯ä¾è³´  
**Privacy**: âœ… ç„¡è³‡æ–™ä¸Šå‚³

---

## Findings Summary

### Recommended Tech Stack

**Phase 1** (Telegram Voice):
```bash
Telegram .oga â†’ FFmpeg â†’ Whisper.cpp â†’ Context injection
```

**Dependencies**:
- `brew install whisper-cpp ffmpeg`
- Model: `~/.whisper-cpp/ggml-base.bin` (142MB)
- Memory: ~500MB during processing

**Phase 2** (Future Voice Assistant):
```bash
Microphone â†’ Porcupine (wake-word) â†’ Whisper.cpp â†’ Claude API â†’ Piper TTS
```

**Additional Dependencies**:
- Porcupine (keyword spotting): ~1MB + Python SDK
- Piper (TTS): ~50MB per voice model

### Resource Requirements

| Component | Memory | Disk | Latency |
|-----------|--------|------|---------|
| Whisper.cpp (base) | 500MB | 142MB | 8s/min |
| Whisper.cpp (streaming) | 800MB | 142MB | 2.1s lag |
| Essentia (with models) | 500MB | 800MB | 2s/3min song |
| Porcupine (keyword) | 10MB | 1MB | <10ms |

### Privacy Model

**Level 2 (Hybrid)** â€” Recommended for mini-agent:
- Sensitive keywords â†’ Local LLM
- General queries â†’ Cloud API (Claude)
- Audio files â†’ Local storage only (memory/media/)

---

## Key Decisions

1. **Primary STT**: Whisper.cppï¼ˆæ¥µç°¡ä¾è³´ã€CLI å‹å–„ã€é€šç”¨æ€§ä½³ï¼‰
2. **Music Analysis**: Essentiaï¼ˆæ¥­ç•Œæ¨™æº–ã€å…§å»ºæ·±åº¦å­¸ç¿’æ¨¡å‹ï¼‰
3. **Integration Mode**: File-based firstï¼ˆTelegram èªéŸ³è¨Šæ¯ï¼‰
4. **No Active Listening**: ä¸æ•´åˆä¸»å‹•éº¥å…‹é¢¨ç›£è½ï¼ˆéš±ç§ + è³‡æºè€ƒé‡ï¼‰

---

## Next Actions

### Immediate (This Week)
- [ ] Install Whisper.cpp: `brew install whisper-cpp`
- [ ] Test basic transcription with sample audio
- [ ] Prototype `plugins/telegram-voice.sh`

### Short-term (1 Month)
- [ ] Implement Telegram voice message transcription
- [ ] Test Chinese transcription accuracy
- [ ] Document in ARCHITECTURE.md

### Mid-term (3 Months)
- [ ] Evaluate Voxtral Mini 4B CLI usability
- [ ] Research Essentia for music library analysis
- [ ] Prototype wake-word detection (Porcupine)

---

## Research Methodology

1. **Web Search** (8 queries):
   - Whisper.cpp macOS ARM64 benchmarks
   - Voxtral Mini 4B WASM/WebGPU capabilities
   - Apple SpeechAnalyzer performance
   - Claude Sonnet audio processing
   - Librosa/Essentia macOS ARM64 support
   - Microphone capture (FFmpeg/SoX)
   - AI agent audio perception patterns
   - Real-time latency benchmarks

2. **Codebase Analysis**:
   - Reviewed `memory/ARCHITECTURE.md` (Perception System)
   - Checked existing plugins structure
   - Verified Telegram integration patterns

3. **Industry Analysis**:
   - Voice AI stack trends (2026)
   - Privacy-first architectures
   - Streaming vs file-based approaches

---

## References

### Official Documentation
- [Whisper.cpp GitHub](https://github.com/ggml-org/whisper.cpp)
- [Apple SpeechAnalyzer WWDC25](https://developer.apple.com/videos/play/wwdc2025/277/)
- [Voxtral Mini 4B - Mistral AI](https://mistral.ai/news/voxtral-transcribe-2)
- [Essentia Documentation](https://essentia.upf.edu/)

### Benchmarks & Comparisons
- [MacStories: Apple Speech APIs vs Whisper](https://www.macstories.net/stories/hands-on-how-apples-new-speech-apis-outpace-whisper-for-lightning-fast-transcription/)
- [Whisper Performance on Apple Silicon](https://www.voicci.com/blog/apple-silicon-whisper-performance.html)
- [Voice AI Stack 2026 - AssemblyAI](https://www.assemblyai.com/blog/the-voice-ai-stack-for-building-agents)

### Integration Guides
- [FFmpeg macOS Audio Capture](https://gist.github.com/ali5h/0541913b220ca09571102a8cd165916c)
- [Whisper.cpp Real-time Transcription](https://www.alibaba.com/product-insights/how-to-run-whisper-cpp-offline-for-real-time-meeting-transcription-on-a-macbook-air-m2.html)
- [2026 Voice AI Trends - Kardome](https://www.kardome.com/resources/blog/voice-ai-engineering-the-interface-of-2026/)

---

## File Structure

```
audio-perception-2026/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ synthesis.md                        # Complete research synthesis
â”œâ”€â”€ perspectives/
â”‚   â”œâ”€â”€ 1-stt-local-solutions.md       # STT options comparison
â”‚   â”œâ”€â”€ 2-audio-analysis-music.md      # Audio analysis tools
â”‚   â””â”€â”€ 3-integration-patterns.md       # Integration architectures
â””â”€â”€ summaries/
    â””â”€â”€ key-findings.yaml               # Structured data summary
```

---

## License & Attribution

Research conducted by Claude Code (Sonnet 4.5) for the mini-agent project.
All referenced tools and frameworks retain their original licenses.
